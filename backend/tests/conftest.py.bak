# Configure logging first
import os
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy import create_engine
import sys
import unittest.mock
from app.api.deps import get_db
from app.core.security.clerk import ClerkTokenData
from app.core.security.dependencies import require_auth
from app.db.base_class import Base
import pytest_asyncio
import pytest
from pathlib import Path
from fastapi.testclient import TestClient
from uuid import uuid4, UUID
import uuid
import logging
from fastapi import Request
from tests.mocks.mock_content_analysis import (
    mock_content_analysis_service,
    mock_analyze_content_async,
)
import app.db.session  # Ensure session module is loaded for sys.modules patching
import httpx
from fastapi import FastAPI
from app.models.tenant import Tenant, KYCStatus

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# PATCH TEST SESSION GLOBALLY BEFORE ANY APP IMPORTS
# Import our test middlewares instead of the regular ones

# Import settings here to ensure environment variables are properly loaded

# For sync operations (testing only)
TEST_DATABASE_URL_SYNC = os.environ.get(
    "TEST_DATABASE_URL_SYNC",
    "postgresql://postgres:postgres@127.0.0.1/conversational_commerce_test",
)

# For async operations
TEST_DATABASE_URL = os.environ.get(
    "TEST_DATABASE_URL",
    "postgresql+asyncpg://postgres:postgres@127.0.0.1/conversational_commerce_test",
)

# Print debug information
logger.info(f"Using sync DB URL: {TEST_DATABASE_URL_SYNC}")
logger.info(f"Using async DB URL: {TEST_DATABASE_URL}")

# Force use of 127.0.0.1 explicitly
FORCED_SYNC_URL = (
    "postgresql://postgres:postgres@127.0.0.1/conversational_commerce_test"
)
FORCED_ASYNC_URL = (
    "postgresql+asyncpg://postgres:postgres@127.0.0.1/conversational_commerce_test"
)

# Create both sync and async engines
try:
    logger.info("Attempting to create engines with configured URLs")
    logger.info(f"Sync URL: {TEST_DATABASE_URL_SYNC}")
    logger.info(f"Async URL: {TEST_DATABASE_URL}")

    # Enhanced engine configuration for improved stability
    sync_engine = create_engine(
        TEST_DATABASE_URL_SYNC,
        pool_size=5,
        max_overflow=10,
        pool_timeout=60,  # Increased from 30s to 60s
        pool_recycle=1800,
        # Remove statement timeout as it's causing schema operation failures
        # But keep idle_in_transaction to prevent connection leaks
        connect_args={
            "options": "-c idle_in_transaction_session_timeout=60000"
        },
    )
    logger.info("Sync engine created successfully")

    async_engine = create_async_engine(
        TEST_DATABASE_URL,
        pool_size=5,
        max_overflow=10,
        pool_timeout=120,  # Increased to 2 minutes
        pool_recycle=1800,
        # For asyncpg, we need to use command_timeout rather than options
        # Significantly increase command_timeout for test environment
        connect_args={
            "command_timeout": 180.0,  # 3 minutes to allow for slower test db operations
            "server_settings": {
                "idle_in_transaction_session_timeout": "60000",  # 60 seconds
                "statement_timeout": "0",  # Disable statement timeout for tests
            },
        },
    )
    logger.info("Async engine created successfully")
except Exception as e:
    logger.error(f"Error creating engines with configured URLs: {e}")
    logger.info("Falling back to hardcoded 127.0.0.1 URLs")
    sync_engine = create_engine(
        FORCED_SYNC_URL,
        pool_size=5,
        max_overflow=10,
        pool_timeout=60,
        pool_recycle=1800,
        connect_args={
            "options": "-c idle_in_transaction_session_timeout=60000"
        },
    )
    async_engine = create_async_engine(
        FORCED_ASYNC_URL,
        pool_size=5,
        max_overflow=10,
        pool_timeout=120,
        pool_recycle=1800,
        connect_args={
            "command_timeout": 180.0,  # 3 minutes to allow for slower test db operations
            "server_settings": {
                "idle_in_transaction_session_timeout": "60000",  # 60 seconds
                "statement_timeout": "0",  # Disable statement timeout for tests
            },
        },
    )
    logger.info("Fallback engines created successfully")

# Set environment variable to indicate we're testing
os.environ["TESTING"] = "true"

# Create session factories
TestingSessionLocal = sessionmaker(
    autocommit=False, autoflush=False, bind=sync_engine)
AsyncTestingSessionLocal = async_sessionmaker(
    async_engine, class_=AsyncSession, expire_on_commit=False
)

# Override the session modules for testing
sys.modules["app.db.session"].SessionLocal = TestingSessionLocal
sys.modules["app.db.session"].engine = sync_engine


# Set environment variables for all tests
@pytest.fixture(scope="session", autouse=True)
def set_test_env_vars():
    """Set additional environment variables for tests"""
    logger.info("Setting test environment variables")
    os.environ["PYTEST_RUNNING"] = "1"
    yield
    logger.info("Clearing test environment variables")
    os.environ.pop("PYTEST_RUNNING", None)


# Debug fixture to run before any test to help diagnose issues
@pytest.fixture(scope="session", autouse=True)
def debug_test_environment():
    """Print debug information about the test environment"""
    logger.info("====== TEST ENVIRONMENT DEBUG INFO ======")
    logger.info(f"Python version: {sys.version}")
    logger.info(f"Test database: {TEST_DATABASE_URL}")
    logger.info(f"TESTING env var: {os.environ.get('TESTING')}")
    logger.info(f"Current working directory: {os.getcwd()}")
    logger.info(f"Path: {os.environ.get('PATH')}")

    # Checking for pytest deadlock culprits
    logger.info("==== Checking for potential deadlock sources =====")
    try:
        import psutil

        logger.info(
            "Memory usage: {:.2f}MB".format(
                psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024
            )
        )
    except ImportError:
        logger.info("psutil not installed, skipping memory check")

    yield
    logger.info("====== TEST ENVIRONMENT DEBUG COMPLETE ======")


# Connection leak checker fixture
@pytest.fixture(scope="session", autouse=True)
def check_leaked_connections():
    """Check for leaked database connections at the end of the test session."""
    # Run the tests
    yield
    
    # Check for leaked connections at the end of the test session
    try:
        from sqlalchemy import text
        with sync_engine.connect() as conn:
            result = conn.execute(text(
                "SELECT count(*) FROM pg_stat_activity WHERE application_name LIKE '%python%'"
            ))
            active_connections = result.scalar()
            if active_connections > 2:  # Allow for some overhead
                logger.warning(f"Possible connection leak detected: {active_connections} connections still open")
                # Log details of connections to help diagnose the leak
                detailed_result = conn.execute(text(
                    """SELECT pid, application_name, client_addr, backend_start, state, 
                       query_start, state_change, wait_event_type, wait_event 
                       FROM pg_stat_activity WHERE application_name LIKE '%python%'"""
                ))
                for conn_info in detailed_result:
                    logger.warning(f"Leaked connection: {conn_info}")
    except Exception as e:
        logger.error(f"Error checking for leaked connections: {e}")
        
    # Attempt to terminate all leaked connections
    try:
        with sync_engine.connect() as conn:
            conn.execute(text(
                """SELECT pg_terminate_backend(pid) FROM pg_stat_activity 
                   WHERE application_name LIKE '%python%' AND pid <> pg_backend_pid()"""
            ))
            logger.info("Attempted to terminate any leaked connections")
    except Exception as e:
        logger.error(f"Error terminating leaked connections: {e}")



# Apply patches to avoid heavy model loading during tests
@pytest.fixture(scope="session", autouse=True)
def patch_content_analysis():
    """Patch content_analysis_service and analyze_content_async to use mocks.
    This prevents downloading heavy models during tests."""
    logger.info("Applying content analysis patches for tests")

    # Patch the content analysis service
    with unittest.mock.patch(
        "app.core.content.content_analysis.content_analysis_service",
        mock_content_analysis_service,
    ):
        # Patch analyze_content_async
        with unittest.mock.patch(
                    unittest.mock.MagicMock(),
                ):
                    logger.info(
                        "Content analysis patches applied successfully")
                    yield

    logger.info("Content analysis patches removed")


# Add the backend directory to Python path
backend_dir = str(Path(__file__).parent.parent)
sys.path.insert(0, backend_dir)

# Set testing environment variable
os.environ["TESTING"] = "True"

# Test data


@pytest_asyncio.fixture(scope="function")
async def test_product(async_db_session, test_tenant, test_user):
    from app.models.product import Product
    from sqlalchemy import text, select

    # Remove any existing test products for idempotency
    await async_db_session.execute(
        text("DELETE FROM products WHERE name = 'Test Product'")
    )
    await async_db_session.commit()

    # Set the tenant context for this session if the GUC is available
    try:
        await async_db_session.execute(
            text(f"SET LOCAL my.tenant_id = '{test_tenant.id}'")
        )
    except Exception:
        pass  # Ignore if GUC not present in test DB

    product = Product(
        id=uuid4(),
        name="Test Product",
        description="A product for testing order creation.",
        price=1000,
        seller_id=test_user.id,
        tenant_id=test_tenant.id,
    )
    async_db_session.add(product)
    await async_db_session.commit()

    # Use select to refresh the product
    stmt = select(Product).where(Product.id == product.id)
    result = await async_db_session.execute(stmt)
    product = result.scalar_one_or_none()

    return product


# Use a fixed UUID for consistent testing
# Consistent test UUID
TEST_USER_ID = UUID("00000000-0000-0000-0000-000000000001")
TEST_USER_EMAIL = "test@example.com"
# Consistent test tenant UUID
TEST_TENANT_ID = UUID("00000000-0000-0000-0000-000000000010")


@pytest.fixture(scope="session")
def db_engine():
    # Create test database tables
    Base.metadata.create_all(bind=sync_engine)
    yield sync_engine
    # Drop test database tables with cascade to avoid dependency errors
    try:
        Base.metadata.drop_all(bind=sync_engine, checkfirst=True)
    except Exception as e:
        # If drop_all fails due to dependencies, use raw SQL with CASCADE
        from sqlalchemy import text
        with sync_engine.connect() as conn:
            conn.execute(text("DROP SCHEMA public CASCADE"))
            conn.execute(text("CREATE SCHEMA public"))


@pytest_asyncio.fixture(scope="session")
async def async_db_engine():
    # Create test database tables using sync engine (async engine can't create tables)
    Base.metadata.create_all(bind=sync_engine)
    yield async_engine
    # Tables are dropped by the sync fixture


@pytest.fixture(scope="function")
def db_session(db_engine):
    """Create a sync session for each test, automatically
    rolling back changes to maintain test isolation."""
    logger.info("[DEBUG] Entering db_session fixture")
    
    # Variables to hold resources that need cleanup
    connection = None
    transaction = None
    session = None
    session_id = str(uuid.uuid4())[:8]
    
    try:
        connection = db_engine.connect()
        transaction = connection.begin()
        session = TestingSessionLocal(bind=connection)
        logger.info(f"[DEBUG] Created sync session {session_id}")
        
        yield session
        
    except Exception as e:
        logger.error(f"[ERROR] Exception in db_session: {e}")
        raise
        
    finally:
        # Always clean up resources in finally block to ensure they run
        logger.info(f"[DEBUG] Cleaning up db_session {session_id}")
        
        # Clean up session
        if session:
            try:
                session.close()
                logger.info(f"[DEBUG] Session {session_id} closed successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error closing session: {e}")
        
        # Roll back transaction
        if transaction:
            try:
                transaction.rollback()
                logger.info(f"[DEBUG] Transaction rolled back successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error rolling back transaction: {e}")
        
        # Close connection
        if connection:
            try:
                connection.close()
                logger.info(f"[DEBUG] Connection closed successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error closing connection: {e}")
                
        logger.info("[DEBUG] Exiting db_session successfully")


@pytest_asyncio.fixture(scope="function")
async def async_db_session():
    """Create an async session for each test, automatically
    rolling back changes to maintain test isolation."""
    logger.info("[DEBUG] Entering async_db_session fixture (attempt 1/3)")
    
    # Retry logic with exponential backoff
    retries = 3
    attempt = 1
    backoff_time = 1
    
    # Variables to hold resources that need cleanup
    conn = None
    trans = None
    session = None
    session_id = str(uuid.uuid4())[:8]
    
    while attempt <= retries:
        try:
            # Ensure any previous resources are properly cleaned up
            if session:
                try:
                    await session.close()
                except Exception as e:
                    logger.warning(f"[WARNING] Error closing previous session: {e}")
                    
            if trans:
                try:
                    await trans.rollback()
                except Exception as e:
                    logger.warning(f"[WARNING] Error rolling back previous transaction: {e}")
                    
            if conn:
                try:
                    await conn.close()
                except Exception as e:
                    logger.warning(f"[WARNING] Error closing previous connection: {e}")
            
            # Start a clean connection transaction
            logger.info(f"[DEBUG] Connecting to database (attempt {attempt}/{retries})")
            conn = await async_engine.connect()
            trans = await conn.begin()
            
            # Create a fresh session to use
            session = AsyncSession(
                bind=conn,
                expire_on_commit=False,
            )
            
            logger.info(f"[DEBUG] Created async session {session_id}")
            logger.info("[DEBUG] Yielding async_db_session")
            yield session
            
            # Always roll back to ensure test isolation
            logger.info(f"[DEBUG] Rolling back async session {session_id}")
            
            # Handle resource cleanup carefully with individual try/except blocks
            try:
                await session.close()
                logger.info(f"[DEBUG] Session {session_id} closed successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error closing session: {e}")
                
            try:
                await trans.rollback()
                logger.info(f"[DEBUG] Transaction rolled back successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error rolling back transaction: {e}")
                
            try:
                await conn.close()
                logger.info(f"[DEBUG] Connection closed successfully")
            except Exception as e:
                logger.warning(f"[WARNING] Error closing connection: {e}")
            
                
            # If we get here, everything worked
            logger.info("[DEBUG] Exiting async_db_session successfully")
            break
        
        except DBAPIError as e:
            if attempt < max_retries - 1:
                logger.warning(f"Database connection error, retrying in {retry_delay}s: {e}")
                await asyncio.sleep(retry_delay)
                # Increment backoff time for next retry
                retry_delay *= 2
            else:
                logger.error(f"Failed to establish database connection after {max_retries} attempts: {e}")
                raise


@pytest.fixture
def client() -> TestClient:
    """Create a test client for the app"""
    # Force test environment for safety
    os.environ["TESTING"] = "true"
    os.environ["ENVIRONMENT"] = "test"

    # Override database settings using environment variables for tests
    os.environ["POSTGRES_SERVER"] = "127.0.0.1"
    os.environ["POSTGRES_USER"] = "postgres"
    os.environ["POSTGRES_PASSWORD"] = "postgres"
    os.environ["POSTGRES_DB"] = "conversational_commerce_test"

    # Create a clean app without problematic middlewares
    from fastapi import FastAPI
    from app.main import (
        register_exception_handlers,
        StorefrontError,
        handle_storefront_error,
    )

    app = FastAPI()
    register_exception_handlers(app)
    app.add_exception_handler(StorefrontError, handle_storefront_error)

    # Override the get_db dependency to use our test session
    async def override_get_db():
        async with AsyncTestingSessionLocal() as session:
            try:
                yield session
            finally:
                await session.close()

    # Override the auth dependency for testing
    async def override_require_auth(request: Request):
        return ClerkTokenData(
            sub=str(TEST_USER_ID), email=TEST_USER_EMAIL, role="seller"
        )

    # Override dependencies
    app.dependency_overrides[get_db] = override_get_db
    app.dependency_overrides[require_auth] = override_require_auth

    # Include API router
    from app.api.v1.api import api_router

    app.include_router(api_router, prefix="/api/v1")

    return TestClient(app)


@pytest.fixture(scope="function")
def auth_headers():
    # Create auth headers with test token and tenant ID
    return {"Authorization": "Bearer test_token", "X-Tenant-ID": str(TEST_TENANT_ID)}


@pytest.fixture(scope="function")
def test_tenant(db_session):
    logger.info("[DEBUG] Entering test_tenant fixture")
    from app.models.tenant import Tenant
    test_tenant = db_session.query(Tenant).filter(
        Tenant.id == TEST_TENANT_ID).first()
    if not test_tenant:
        test_tenant = Tenant(
            id=TEST_TENANT_ID,
            name="Test Tenant",
            subdomain=f"test-{uuid.uuid4()}",
            is_active=True,
            phone_number="+2348000000001",  # Required field
            country_code="NG",
            kyc_status=KYCStatus.NOT_STARTED,
            storefront_enabled=True,
        )
        db_session.add(test_tenant)
        db_session.commit()
    logger.info("[DEBUG] Yielding test_tenant")
    return test_tenant


@pytest_asyncio.fixture(scope="function")
async def test_user(async_db_session, test_tenant):
    logger.info("[DEBUG] Entering test_user fixture")
    from app.models.user import User
    from app.models.product import Product
    from app.models.tenant import Tenant
    from sqlalchemy import text
    await async_db_session.execute(text("DELETE FROM products"))
    await async_db_session.commit()
    await async_db_session.execute(text("DELETE FROM users"))
    await async_db_session.commit()
    tenant = await async_db_session.get(Tenant, test_tenant.id)
    if not tenant:
        tenant = Tenant(
            id=test_tenant.id,
            name=test_tenant.name,
            subdomain=getattr(test_tenant, "subdomain", "testtenant"),
            phone_number=getattr(
                test_tenant, "phone_number", "+2348000000001"),
            country_code=getattr(test_tenant, "country_code", "NG"),
            kyc_status=getattr(test_tenant, "kyc_status",
                               KYCStatus.NOT_STARTED),
            storefront_enabled=getattr(
                test_tenant, "storefront_enabled", True),
            is_active=getattr(test_tenant, "is_active", True),
            custom_domain=getattr(test_tenant, "custom_domain", None),
            domain_verified=getattr(test_tenant, "domain_verified", False),
            domain_verification_token=getattr(
                test_tenant, "domain_verification_token", None),
            kyc_data=getattr(test_tenant, "kyc_data", None),
            kyc_documents=getattr(test_tenant, "kyc_documents", None),
            kyc_updated_at=getattr(test_tenant, "kyc_updated_at", None),
            whatsapp_number=getattr(test_tenant, "whatsapp_number", None),
            settings=getattr(test_tenant, "settings", None),
            updated_at=getattr(test_tenant, "updated_at", None),
            email=getattr(test_tenant, "email", None),
        )
        async_db_session.add(tenant)
        await async_db_session.commit()
        await async_db_session.refresh(tenant)
    test_user = User(
        id=UUID("00000000-0000-0000-0000-000000000001"),
        email=TEST_USER_EMAIL,
        is_seller=True,
        tenant_id=test_tenant.id,
    )
    async_db_session.add(test_user)
    other_user = User(
        id=UUID("00000000-0000-0000-0000-000000000002"),
        email="other@example.com",
        is_seller=True,
        tenant_id=test_tenant.id,
    )
    async_db_session.add(other_user)
    await async_db_session.commit()
    await async_db_session.refresh(test_user)
    await async_db_session.refresh(other_user)
    logger.info("[DEBUG] Yielding test_user")
    return test_user


@pytest.fixture
def other_auth_headers():
    return {"Authorization": "Bearer other_token"}


@pytest_asyncio.fixture(scope="function")
async def async_client():
    from app.main import app  # Import the FastAPI app
    async with httpx.AsyncClient(app=app, base_url="http://testserver") as ac:
        yield ac
